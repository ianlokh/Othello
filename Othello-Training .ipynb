{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "085802a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from collections import deque\n",
    "import gym\n",
    "import othello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88f2ef30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 19:28:03.147380: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, clone_model\n",
    "from tensorflow.keras.layers import Dense, Activation, LeakyReLU, BatchNormalization, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "os.environ['TF_GPU_THREAD_COUNT'] = '4' #if not hvd_utils.is_using_hvd() else str(hvd.size())\n",
    "\n",
    "from rl.agents.dqn import DQNAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed9ffcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n",
      "Metal device set to: AMD Radeon Pro 555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 19:28:07.607142: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-24 19:28:07.607880: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-09-24 19:28:07.607936: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-24 19:28:07.608111: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "def set_gpu(gpu_ids_list):\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            gpus_used = [gpus[i] for i in gpu_ids_list]\n",
    "            tf.config.set_visible_devices(gpus_used, 'GPU')\n",
    "            for gpu in gpus_used:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "        except RuntimeError as e:\n",
    "            # Visible devices must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "\n",
    "\n",
    "set_gpu([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "183fe88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0.0, 64.0, (64,), float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_name = \"othello:othello-v0\"\n",
    "env = gym.make(env_name)\n",
    "env.observation_space['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b24cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_actions = env.action_space.n\n",
    "nb_observations = env.observation_space['state'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1660899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 16)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,488\n",
      "Trainable params: 41,232\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1,) + nb_observations))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "\n",
    "model.add(Dense(32))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "529aa8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = clone_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a608df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "BATCH_SIZE = 128\n",
    "epsilon = 1.0\n",
    "EPSILON_REDUCE = 0.995\n",
    "LEARNING_RATE = 0.001\n",
    "GAMMA = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ea9ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_action_selection(model, epsilon, observation):\n",
    "    \n",
    "    if np.random.random() > epsilon:\n",
    "        \n",
    "        observation= tf.expand_dims(observation, axis=0)\n",
    "    \n",
    "        prediction = model.predict(observation, verbose=0)  # [0.4, 0.6]\n",
    "        action = np.argmax(prediction)\n",
    "    else:\n",
    "        action = np.random.randint(0, env.action_space.n)\n",
    "        \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c34f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = deque(maxlen=20000)\n",
    "update_target_model = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a3b536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replay(replay_buffer, batch_size, model, target_model):\n",
    "    \n",
    "    if len(replay_buffer) < batch_size:\n",
    "        return\n",
    "    \n",
    "    samples = random.sample(replay_buffer, batch_size)\n",
    "    \n",
    "    target_batch = []\n",
    "    zipped_samples = list(zip(*samples))\n",
    "    states, actions, rewards, new_states, dones = zipped_samples\n",
    "    targets = target_model.predict(np.array(states), verbose = 0)\n",
    "    q_values = model.predict(np.array(new_states), verbose = 0)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        q_value = max(q_values[i][0])\n",
    "        target = targets[i].copy()\n",
    "        \n",
    "        if dones[i]:\n",
    "            target[0][actions[i]] = rewards[i]\n",
    "        else:\n",
    "            target[0][actions[i]] = rewards[i] + q_value*GAMMA\n",
    "        \n",
    "        target_batch.append(target)\n",
    "    \n",
    "    model.fit(np.array(states), np.array(target_batch), epochs=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5938dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_handler(epoch, update_target_mode, model, target_model):\n",
    "    \n",
    "    if epoch > 0 and epoch % update_target_model == 0:\n",
    "        target_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "554fe87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=(Adam(learning_rate=LEARNING_RATE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "385ad888",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Invalid Next Action",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m     12\u001b[0m     action \u001b[38;5;241m=\u001b[39m  epsilon_greedy_action_selection(model, epsilon, observation)\n\u001b[0;32m---> 13\u001b[0m     next_observation, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     next_observation \u001b[38;5;241m=\u001b[39m next_observation[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m64\u001b[39m))\n\u001b[1;32m     15\u001b[0m     replay_buffer\u001b[38;5;241m.\u001b[39mappend((observation, action, reward, next_observation, done))\n",
      "File \u001b[0;32m~/miniforge3/envs/tfrl-metal_py39/lib/python3.9/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tfrl-metal_py39/lib/python3.9/site-packages/gym/wrappers/env_checker.py:37\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_step_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m~/miniforge3/envs/tfrl-metal_py39/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:214\u001b[0m, in \u001b[0;36menv_step_passive_checker\u001b[0;34m(env, action)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"A passive check for the environment step, investigating the returning data then returning the data unchanged.\"\"\"\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# We don't check the action as for some environments then out-of-bounds values can be given\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    216\u001b[0m     result, \u001b[38;5;28mtuple\u001b[39m\n\u001b[1;32m    217\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpects step result to be a tuple, actual type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
      "File \u001b[0;32m~/PycharmProjects/othello/othello/envs/othello_env.py:597\u001b[0m, in \u001b[0;36mOthelloEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    584\u001b[0m x_ind, y_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action_to_pos(action)\n\u001b[1;32m    586\u001b[0m \u001b[38;5;66;03m# # if position is an invalid position, then reward = -1\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;66;03m# if not self.check_board_pos(x_ind, y_ind):\u001b[39;00m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;66;03m#     reward = -1\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;66;03m# add the token to the board and get the number of tokens flipped as the reward\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;66;03m# change the reward to tune the training of the agents\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (x_ind, y_ind) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_possible_actions, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Next Action\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_to_board(x_ind, y_ind, player)\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# set the next_player variable\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Invalid Next Action"
     ]
    }
   ],
   "source": [
    "best_so_far = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    observation, info = env.reset()\n",
    "    \n",
    "    observation = observation[\"state\"].reshape((1,64))\n",
    "    done = False\n",
    "    \n",
    "    points = 0\n",
    "    while not done:\n",
    "        action =  epsilon_greedy_action_selection(model, epsilon, observation)\n",
    "        next_observation, reward, done, truncated, info = env.step(action)\n",
    "        next_observation = next_observation[\"state\"].reshape((1,64))\n",
    "        replay_buffer.append((observation, action, reward, next_observation, done))\n",
    "        \n",
    "        observation = next_observation\n",
    "        points += 1\n",
    "        \n",
    "        replay(replay_buffer, BATCH_SIZE, model, target_model)\n",
    "        \n",
    "    epsilon *= EPSILON_REDUCE # eps * 0.995\n",
    "    \n",
    "    update_model_handler(epoch, update_target_model, model, target_model)\n",
    "    \n",
    "    if points > best_so_far:\n",
    "        best_so_far = points\n",
    "        \n",
    "    if epoch%25 == 0:\n",
    "        print(f\"{epoch}: POINTS: {points} eps: {epsilon} BSF: {best_so_far}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5278441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
