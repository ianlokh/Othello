{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23dc9e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from collections import deque\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf17926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 16:22:01.424338: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, clone_model\n",
    "from tensorflow.keras.layers import Dense, Activation, LeakyReLU, BatchNormalization, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "os.environ['TF_GPU_THREAD_COUNT'] = '4' #if not hvd_utils.is_using_hvd() else str(hvd.size())\n",
    "\n",
    "from rl.agents.dqn import DQNAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bebccc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: AMD Radeon Pro 555\n",
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 16:22:15.827054: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-02 16:22:15.827668: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-02 16:22:15.827730: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-02 16:22:15.827898: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "def set_gpu(gpu_ids_list):\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            gpus_used = [gpus[i] for i in gpu_ids_list]\n",
    "            tf.config.set_visible_devices(gpus_used, 'GPU')\n",
    "            for gpu in gpus_used:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "        except RuntimeError as e:\n",
    "            # Visible devices must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "\n",
    "\n",
    "set_gpu([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d934043a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0.0, 64.0, (64,), float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_name = \"othello:othello-v0\"\n",
    "env = gym.make(env_name, render_mode=\"human\")\n",
    "env.observation_space['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd729ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 64\n"
     ]
    }
   ],
   "source": [
    "# 4 observations\n",
    "num_observations = env.observation_space['state'].shape[0]\n",
    "num_actions = env.action_space.n\n",
    "print(num_observations, num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba2f248f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/stb/miniforge3/envs/tfrl-metal_py39/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py:562: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1, 32)             1056      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1, 64)             2112      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1, 64)            256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 1, 64)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1, 128)            8320      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1, 128)            16512     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1, 64)             8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1, 64)            256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 1, 64)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1, 64)             2112      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,040\n",
      "Trainable params: 42,784\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, input_shape=(1, num_observations), activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(num_actions, activation=tf.keras.activations.linear)\n",
    "])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daa4ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = clone_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c70618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "BATCH_SIZE = 128\n",
    "epsilon = 1.0\n",
    "EPSILON_REDUCE = 0.995\n",
    "LEARNING_RATE = 0.001\n",
    "GAMMA = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "311434e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_action_selection(model, epsilon, observation, possible_actions):\n",
    "    \n",
    "    # set the mask\n",
    "    mask = np.array([[True] * 64], dtype=bool)  # shape = (1, 64)\n",
    "    for row, col in possible_actions:\n",
    "        mask[0][(row * 8) + col] = False  # do not mask a possible action\n",
    "\n",
    "    if np.random.random() > epsilon:        \n",
    "        observation = tf.expand_dims(observation, axis=0)\n",
    "        observation = tf.keras.backend.eval(observation)\n",
    "        \n",
    "        prediction = model.predict(observation, verbose=0)  # [0.4 ... 0.6] (64, )       \n",
    "        prediction = tf.where(mask, -1e9, prediction)  # same as torch.masked_fill\n",
    "        prediction = tf.nn.softmax(prediction, axis=None, name=None)  # all masked prob equal to 0 after this step\n",
    "        \n",
    "        action = tf.argmax(prediction[0], axis=1)\n",
    "        action = int(tf.keras.backend.eval(action))\n",
    "        \n",
    "        print(\"predict\", action)\n",
    "\n",
    "    else:\n",
    "        action = random.choice(list(possible_actions))\n",
    "        action = (action[0] * 8) + action[1]        \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f66c5d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = deque(maxlen=20000)\n",
    "update_target_model = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad44acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replay(replay_buffer, batch_size, model, target_model):\n",
    "    \n",
    "    if len(replay_buffer) < batch_size:\n",
    "        return\n",
    "    \n",
    "    samples = random.sample(replay_buffer, batch_size)\n",
    "    \n",
    "    target_batch = []\n",
    "    zipped_samples = list(zip(*samples))\n",
    "    states, actions, rewards, new_states, dones = zipped_samples\n",
    "    \n",
    "    targets = target_model.predict(np.array(states), verbose = 0)\n",
    "    q_values = model.predict(np.array(new_states), verbose = 0)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        q_value = max(q_values[i][0])\n",
    "        target = targets[i].copy()\n",
    "                \n",
    "        if dones[i]:\n",
    "            target[0][actions[i]] = rewards[i]\n",
    "        else:\n",
    "            target[0][actions[i]] = rewards[i] + q_value*GAMMA\n",
    "        \n",
    "        target_batch.append(target)\n",
    "    \n",
    "    history = model.fit(np.array(states), np.array(target_batch), epochs=3, verbose=0)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f2a9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_handler(epoch, update_target_model, model, target_model):\n",
    "    \n",
    "    if epoch > 0 and epoch % update_target_model == 0:\n",
    "        target_model.set_weights(model.get_weights())\n",
    "        print('update target_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57f63872",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ebe58c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e6802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# done = False\n",
    "\n",
    "# observation, info = env.reset()\n",
    "# observation = observation[\"state\"].reshape(1,64)\n",
    "# next_possible_actions = info[\"next_possible_actions\"]\n",
    "\n",
    "# action =  epsilon_greedy_action_selection(model, 0.0, observation, next_possible_actions)\n",
    "# print(action)\n",
    "\n",
    "# next_observation, reward, done, truncated, info = env.step(action)\n",
    "# next_observation = next_observation[\"state\"].reshape((1,64))\n",
    "# next_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a88995e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for epoch in range(EPOCHS):\n",
    "#     replay_buffer.append((observation, action, reward, next_observation, done))\n",
    "\n",
    "# observation = next_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451b36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = replay(replay_buffer, BATCH_SIZE, model, target_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd13030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_model_handler(1, update_target_model, model, target_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a43495",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_so_far = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    observation, info = env.reset()\n",
    "    observation = observation[\"state\"].reshape((1,64))\n",
    "    next_possible_actions = info[\"next_possible_actions\"]\n",
    "    \n",
    "    done = False\n",
    "\n",
    "    points = 0\n",
    "    while not done:\n",
    "        action =   epsilon_greedy_action_selection(model, epsilon, observation, next_possible_actions)\n",
    "#         print(next_possible_actions, action)\n",
    "        \n",
    "        next_observation, reward, done, truncated, info = env.step(action)\n",
    "        next_observation = next_observation[\"state\"].reshape((1,64))\n",
    "        next_possible_actions = info[\"next_possible_actions\"]\n",
    "\n",
    "        replay_buffer.append((observation, action, reward, next_observation, done))\n",
    "        \n",
    "        observation = copy.deepcopy(next_observation)\n",
    "        points += reward\n",
    "\n",
    "    hist = replay(replay_buffer, BATCH_SIZE, model, target_model)\n",
    "    if not(hist is None):\n",
    "        print(\"Loss: \", hist.history['loss'], \"Accuracy:\", hist.history['accuracy'],)\n",
    "        \n",
    "    epsilon *= EPSILON_REDUCE # eps * 0.995\n",
    "    \n",
    "    update_model_handler(epoch, update_target_model, model, target_model)\n",
    "    \n",
    "    if points > best_so_far:\n",
    "        best_so_far = points\n",
    "        \n",
    "    if epoch%25 == 0:\n",
    "        print(f\"{epoch}: POINTS: {points} eps: {epsilon} BSF: {best_so_far}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6155ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
